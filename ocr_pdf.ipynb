{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdfLink.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \n\u001b[1;32m     69\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_misspelled_words.txt\u001b[39m\u001b[38;5;124m'\u001b[39m  \n\u001b[0;32m---> 70\u001b[0m \u001b[43mprocess_all_pdfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 53\u001b[0m, in \u001b[0;36mprocess_all_pdfs\u001b[0;34m(csv_file_path, output_file)\u001b[0m\n\u001b[1;32m     49\u001b[0m pdf_links \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()  \n\u001b[1;32m     51\u001b[0m all_misspelled_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdf_url \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_links\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m     pdf_id \u001b[38;5;241m=\u001b[39m pdf_url\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "def load_vietnamese_dictionary(dic_file_path):\n",
    "    vietnamese_dict = set()\n",
    "    with open(dic_file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#') or line.strip() == '':\n",
    "                continue\n",
    "            word = line.split('/')[0].strip()\n",
    "            vietnamese_dict.add(word)\n",
    "    return vietnamese_dict\n",
    "vietnamese_dictionary = load_vietnamese_dictionary('vi_VN.dic')  \n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-ZÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚĂĐĨŨƠàáâãèéêìíòóôõùúăđĩũơƯăắặằẳẵâầấậẩẫêềếệểễôồốộổỗơờởỡợừữửựụ0-9.,;:/]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "def process_pdf(url):\n",
    "    response = requests.get(url)\n",
    "    pdf_path = \"temp_document.pdf\"\n",
    "    with open(pdf_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    \n",
    "    pages = convert_from_path(pdf_path)\n",
    "    \n",
    "    full_text = \"\"\n",
    "    \n",
    "    for page in tqdm(pages, desc=\"Processing Pages\"):\n",
    "        img = np.array(page)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        contrast_img = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)\n",
    "        text = pytesseract.image_to_string(contrast_img, lang='vie')\n",
    "        full_text += text + \"\\n\"\n",
    "    \n",
    "    cleaned_text = clean_text(full_text)\n",
    "    return cleaned_text\n",
    "\n",
    "def detect_misspellings(text, dictionary):\n",
    "    misspelled_words = []\n",
    "    for word in text.split():\n",
    "        if word not in dictionary:\n",
    "            misspelled_words.append(word)\n",
    "    return misspelled_words\n",
    "\n",
    "def process_all_pdfs(csv_file_path, output_file):\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    pdf_links = df['URL'].tolist()  \n",
    "\n",
    "    all_misspelled_words = set()\n",
    "\n",
    "    for pdf_url in tqdm(pdf_links):\n",
    "        print(f\"Processing {pdf_url}\")\n",
    "        pdf_id = pdf_url.split('/')[-1]\n",
    "        cleaned_text = process_pdf(pdf_url)\n",
    "\n",
    "        with open(f\"pdf/{pdf_id}.txt\", \"w\", encoding=\"utf-8\") as f_cleaned:\n",
    "            f_cleaned.write(cleaned_text)\n",
    "\n",
    "        misspelled_words = detect_misspellings(cleaned_text, vietnamese_dictionary)\n",
    "        all_misspelled_words.update(misspelled_words)\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as f_out:\n",
    "        for word in sorted(all_misspelled_words):  \n",
    "            f_out.write(f\"{word}\\n\")\n",
    "\n",
    "csv_file_path = 'pdfLink.csv'  \n",
    "output_file = 'all_misspelled_words.txt'  \n",
    "process_all_pdfs(csv_file_path, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
